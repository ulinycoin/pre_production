# robots.txt for LocalPDF
# https://localpdf.online

User-agent: *
Allow: /

# AI Bots - Explicit Allow for Generative Engine Optimization
User-agent: OAI-SearchBot
Allow: /

User-agent: PerplexityBot
Allow: /

User-agent: GoogleBot-Extended
Allow: /

# Sitemaps
Sitemap: https://localpdf.online/sitemap-index.xml

# Bingbot - Moderate crawling speed
User-agent: Bingbot
Crawl-delay: 1

# YandexBot - Conservative crawling for European/Russian markets
User-agent: YandexBot
Crawl-delay: 1

# Disallow app routes (hash-based SPA)
Disallow: /app

# Allow all tool pages
Allow: /merge-pdf
Allow: /split-pdf
Allow: /compress-pdf
Allow: /protect-pdf
Allow: /ocr-pdf
Allow: /watermark-pdf
Allow: /add-text-pdf
Allow: /edit-text-pdf
Allow: /sign-pdf
Allow: /organize-pdf
Allow: /rotate-pdf
Allow: /delete-pages-pdf
Allow: /extract-pages-pdf
Allow: /images-to-pdf
Allow: /pdf-to-images
Allow: /pdf-to-word
Allow: /word-to-pdf
Allow: /tables-pdf
Allow: /add-form-fields-pdf
Allow: /extract-images-pdf
Allow: /flatten-pdf
Allow: /legal-privacy-pdf
Allow: /finance-privacy-pdf
Allow: /medical-privacy-pdf
Allow: /de
Allow: /ja
Allow: /de/
Allow: /ja/

# Allow informational pages
Allow: /about
Allow: /privacy
Allow: /terms
Allow: /learn
Allow: /comparison

# Allow blog pages
Allow: /blog

# Crawl-delay (be nice to search engines)
Crawl-delay: 1
